---
title: "Climate Change Optimized Species Portfolio for Reforestation Planning:PEM"
author: "Will MacKenzie and Kiri Daust"
date: "17/05/2020"
output:
  html_document:
    fig_caption: yes
    theme: lumen
    toc: yes
  pdf_document: default
  #bookdown::html_document2:
  word_document: default
    
---

```{r setup, include=FALSE, message = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
require(dplyr)
require(ggplot2)
require(MASS)
require(magrittr)
require(foreach)
require(reshape2)
require(reticulate)
require(Rcpp)
library(gridExtra)
library(data.table)
library(scales)
library(tidyr)
library(magrittr)
library(ggthemes)
library(flextable)
require(rgdal)
require(tmap)
library(sf)
require(tufte)
require(Hmisc)
require(janitor)
require(tidyverse)
require(Rmisc)
require(bookdown)
require(raster)
require(webshot2)
```



```{r read in  portfolio functions}
##Source functions for growth simulations (C++), Portfolio optimization (Python) and CCISS analysis (R)
sourceCpp("./CppFunctions/SimGrowth.cpp")
source_python("./PythonFns/PortfolioOptimisation.py")
source("CCISS_Fns.R")
```

```{r load pem}
##Set drive with cloud data
if(dir.exists("C:/users/whmacken/Sync")){
  cloud_dir <- "C:/users/whmacken/Sync/CCISS_data/"
}else{
  cloud_dir <- "C:/Users/kirid/Sync/CCISS_data/"
}

pem_name <- "PEM_QU_SBSdw2_1_Polygons2"
pemOrig <- st_read(dsn = paste0(cloud_dir,"PortfolioFiles/QuesnelPem"), layer = pem_name)
pemBGC <- unique(paste0(pemOrig$Bgc_Zone,pemOrig$Bgc_Subzon,pemOrig$Bgc_Vrt))
pem <- pemOrig[pemOrig$Site_S1 != 0, c("AREA","PEM_QU_ID","Sdec_1","Site_S1","Sdec_2","Site_S2","Sdec_3","Site_S3")]
pem <- data.table(pem)
pem <- pem[,.(geometry = st_union(geometry), AREA = sum(AREA)), by = .(Sdec_1,Site_S1,Sdec_2,Site_S2,Sdec_3,Site_S3)]
pem[,PolyID := seq_along(Sdec_1)]
pem <- st_as_sf(pem)
# pts <- st_sample(pem, size = rep(20, nrow(pem)), type = "random") %>% st_as_sf()
# pts$ID <- rep(pem$PolyID, each = 20)
# out <- cbind(pts$ID, st_coordinates(pts)) %>% as.data.table()
# dem <- raster("D:/Kiri 2019/Data/bc25fill")
# pts <- st_transform(pts, st_crs(dem))
# out$el <- raster::extract(dem,pts)
# out <- out[,.(ID1 = V1,ID2 = seq_along(Y),lat = Y,long = X, el)]
# fwrite(out,"PemSamplePts.csv")

pemData <- st_drop_geometry(pem)
t1 <- melt(pemData, id.vars = "PolyID")
t1 <- separate(t1, variable, into = c("Type","Num"), sep = "_")
t1[,Num := gsub("S","",Num)]
pemData <- data.table::dcast(t1,PolyID + Num ~ Type)
```


```{r load species data}
##Load data and run CCISS functions (if necessary)

inputDatName <- "PemSamplePts_90 GCMsMSY.csv" ##generated in ClimateBC for all variable and all future climate scenarios

###Read in data
SuitTable <- fread("InputsGit/Feasibility_v11_21.csv") ##tree spp suitability
SuitTable <- unique(SuitTable)
SuitNew <- fread("InputsGit/Feas_toAdd.csv")

colnames(SuitTable)[2:4] <- c("SS_NoSpace","Spp","Suitability")
SuitTable <- SuitTable[,c("BGC","SS_NoSpace","Spp","Suitability")]
SuitTable <- rbind(SuitTable, SuitNew)
#remove <- c("Mb", "Ra", "Ep", "Bp", "Act", "Bc", "Oa", "Oc", "Og", "Ol", "On", "Ot", "Oy", "Pc", "Ps", "Pz", "Qb", "Qc", "Qd", "Qg", "Qx", "Qz", "Yp") 
## temporary remove since no SI information available yet
#SuitTable <- SuitTable %>% filter(!Spp %in% remove)

SIBEC <- fread("InputsGit/PredSI_May2020.csv") 
SIBECnew <- fread("InputsGit/SI_to_add.csv")
SIBEC <- rbind(SIBEC, SIBECnew)
###import SI data (currently from BART)

SIBEC <- SIBEC[,c("SS_NoSpace","Spp","SIPred")] %>% set_colnames(c("SS_NoSpace","TreeSpp","MeanPlotSiteIndex"))

eda <- fread("InputsGit/Edatopic_v11_20.csv")
eda <- unique(eda[is.na(Special),.(BGC,SS_NoSpace, Edatopic)])

if(file.exists(paste0(cloud_dir,"CCISSPred.Rdata"))){
  load(paste0(cloud_dir,"CCISSPred.Rdata"))
}else{
  ### run CCISS function to predict Site Series
  load(paste0(cloud_dir, "WNAv11_35_VAR_SubZone_ranger.Rdata"))
  Edatope <- fread("./InputsGit/Edatopic_v11_20.csv",data.table = F)
  rawDat <- fread(paste0(cloud_dir,"PortfolioFiles/",inputDatName),data.table = F)
  rawDat$ID2 <- pemBGC
  CCISSPred <- CCISS_Spp(Y1 = rawDat,BGCmodel = BGCmodel,E1 = Edatope)
  save(CCISSPred, file = paste0(cloud_dir,"CCISSPred.Rdata"))
}

SSPredOrig <- as.data.table(CCISSPred[[1]])
colnames(SSPredOrig)[1] <- "MergedBGC"

```
  

```{r colours}
##Colour development for species 

cols <- fread("./InputsGit/PortfolioSppColours.csv")
cols <- cols[HexColour != "",]
myPal <- cols$HexColour
names(myPal) <- cols$TreeCode


library(unikn)
seecol(myPal, hex = T, rgb = F)
```



```{r CCISS predictions}
#Function to clean and summarise SIBEC and CCISS data into MeanSI and MeanSuitability
##function to clean data and summarise 
cleanData <- function(SSPredAll,SIBEC,SuitTable,SNum,Trees,timePer){
  SSPred <- SSPredAll[SiteNo == SNum,] ###subset
  
  ##Merge SIBEC data
  SIBEC <- SIBEC[TreeSpp %in% Trees,]
  SSPred <- SSPred[SSPred$FuturePeriod %in% timePer,]
  SSPred <- SSPred[,c(6,3,4)]
  SSPred <- merge(SSPred, SIBEC, by = "SS_NoSpace", all.x = TRUE)
  
  
  ###Add rows for species with missing SI - mostly US units here
  add <- foreach(Year = unique(SSPred$FuturePeriod), .combine = rbind) %do%{
    byYear <- SSPred[SSPred$FuturePeriod == Year,]
    foreach(SS = unique(byYear$SS_NoSpace), .combine = rbind) %do%{
      bySS <- byYear[byYear$SS_NoSpace == SS,]
      missing <- Trees[!Trees %in% bySS$TreeSpp]
      new <- bySS[rep(1,length(missing)),]
      new$TreeSpp <- missing
      new
    }
  }
  if(!is.null(add)){
    if(nrow(add) > 0){
      add$MeanPlotSiteIndex <- 5 ##Set missing SI
      SSPred <- rbind(SSPred, add)
    }
  } 
  
  
  SSPred <- SSPred[!is.na(SSPred$TreeSpp),]
  colnames(SSPred)[4] <- "Spp"
  
  ##Add suitability
  SSPred <- merge(SSPred, SuitTable, by = c("SS_NoSpace","Spp"), all.x = TRUE)
  SSPred$Suitability[is.na(SSPred$Suitability)] <- 5
  
  temp <- SIBEC[SIBEC$SS_NoSpace == selectBGC,]
  if(nrow(temp) == 0){
    return(NULL)
  }
  ###Create current data
  current <- temp %>% 
    merge(SuitTable, by.x = c("TreeSpp","SS_NoSpace"), by.y = c("Spp","SS_NoSpace"), all.x = TRUE) %>%
    unique()
  
  ###check that there aren't errors in the table
  temp <- aggregate(SS_NoSpace ~ TreeSpp, current, FUN = length)
  if(any(temp$SS_NoSpace > 1)){
    stop("There are partial duplicates in the suitablity table. Please fix them. :)")
  }
  
  current <- data.frame(Spp = current$TreeSpp, FuturePeriod = 2000, 
                        MeanSI = current$MeanPlotSiteIndex, MeanSuit = current$Suitability)
  
  missing <- Trees[!Trees %in% current$Spp]
  if(length(missing) > 0){
    new <- current[rep(1,length(missing)),]
    new$Spp <- missing
    new$MeanSI <- 10
    new$MeanSuit <- 5
    current <- rbind(current, new)
  }
  
  ##Summarise data- average SI and Suit weighted by SSProb
  SS.sum <- SSPred[,.(MeanSI = sum(MeanPlotSiteIndex*(SSprob/sum(SSprob))),
                      MeanSuit = round(sum(Suitability*(SSprob/sum(SSprob))), digits = 0)),
                   by = .(Spp,FuturePeriod)]
  
  SS.sum <- rbind(SS.sum, current)
  SS.sum <- SS.sum[SS.sum$FuturePeriod %in% timePer,]
  ###not sure what we were doing here?
  SS.sum$MeanSI[SS.sum$MeanSuit == 4] <- 5
  SS.sum$MeanSI[SS.sum$MeanSuit == 5] <- 0
  SS.sum$MeanSuit[SS.sum$MeanSuit == 5] <- 4
  SS.sum <- unique(SS.sum)
  SS.sum <- SS.sum[order(SS.sum$Spp,SS.sum$FuturePeriod),]
  #SS.sum$MeanSuit[is.na(SS.sum$MeanSuit)] <- 3
  return(SS.sum)
}

combineList <- function(...) {##Combine multiple dataframe in foreach loop
  mapply(FUN = rbind, ..., SIMPLIFY=FALSE)
}


SS_Subset <- function(SSPredOrig, pos = "01"){
  SSPredFull <- SSPredOrig[grep(pos,SSPredOrig$SSCurrent),]
  SSPredFull$CurrBGC <- gsub("/.*","", SSPredFull$SSCurrent)
  
  SSPredFull <- SSPredFull[,c("MergedBGC", "Source", "SS_NoSpace", "SSprob", "SSCurrent", 
                            "FuturePeriod", "SiteNo","CurrBGC")]
  
  ##remove cases where not all timeperiods available
  SSPredFull <- as.data.table(SSPredFull)
  temp <- SSPredFull[,.(Num = length(unique(FuturePeriod))), by = c("SiteNo","SSCurrent")]
  temp <- temp[Num == 3,-c("Num")]
  SSPredFull <- SSPredFull[temp,on = c("SiteNo","SSCurrent")]
  SSPredFull[,SiteNo := as.numeric(SiteNo)]
}

loopCombine2 <- function(a,b){
  G <- rbind(a$pemSum,b$pemSum)
  df <- rbind(a$allDat,b$allDat)
  return(list(pemSum = G, allDat = df))
}

loopCombine <- function(a,b){
  G <- rbind(a$GraphDat,b$GraphDat)
  df <- rbind(a$MaxS,b$MaxS)
  return(list(GraphDat = G, MaxS = df))
}

ef_plot <- function(outAll){
  efAll <- outAll$GraphDat
  intDat <- outAll$MaxS
  efAll$variable <- factor(efAll$variable, levels = sort(unique(as.character(efAll$variable))))
  ggplot(efAll[efAll$variable != "RealRet",],aes(x = Sd, y = value,group = variable))+
    geom_area(aes(fill = variable), size = 0.00001, col = "grey50", stat = "identity")+
    colScale +
    geom_vline(data = intDat[intDat$Spp == "Sd",], aes(xintercept = value,colour = "blue"), 
               linetype = "twodash", size = .75)+
    geom_vline(data = intDat[intDat$Spp == "Sd",], aes(xintercept = SetRet,colour = "grey52"),
               linetype = "dashed", size = .75)+
    geom_line(data = efAll[efAll$variable == "RealRet",], 
              aes(x = Sd, y = value,colour = "black"),linetype = "F1",size = .75)+
    scale_colour_identity(name = "", guide = 'legend', labels = c("Return","MaxSharpe","90%"))+
    scale_x_reverse() +
    xlab("Max Return --> Minimized Risk")+
    ylab("Portfolio Ratio")+
    guides(fill=guide_legend("Species"))+
    theme_few()+
    facet_wrap(.~Unit, scales = "free_x")
}

MS_plot <- function(Current,Future){
  curr <- as.data.table(Current$MaxS)
  fut <- as.data.table(Future$MaxS)
  colnames(curr)[1] <- "CurrentMS"
  colnames(fut)[c(1,5)] <- c("FutureMS","Future90%")
  
  dat <- curr[fut, on = c("Unit","Spp")]
  dat <- dat[,.(Unit,Spp,CurrentMS,FutureMS,`Future90%`)]
  dat <- melt(dat, id.vars = c("Unit","Spp"))
  dat <- dat[!Spp %in% c("Sd","RealRet"),]
  
  ggplot(dat, aes(x = variable, y = value, group = Spp, fill = Spp))+
    geom_bar(stat = "identity")+
    colScale+
    facet_wrap(.~Unit)+
    labs(x = "Portfolio Type", y = "Portfolio Ratio")+
    guides(fill=guide_legend("Species"))+
    theme_few()+
    theme(axis.text.x = element_text(angle = 90))
}

```



```{r model parameters, out.width=8, results = 'hold'}
### Probabilities attached to each suitability
SuitProb <- data.frame("Suit" = c(1,2,3,4), "ProbDead" = c(0.5,0.5,1,4), 
                       "NoMort" = c(70,60,50,30)) ####ProbDead- out of 100 trees, how many will die each year at each suitability. NoMort- Percent of time no mortality

##Set minimum weighting for any species to appear in portfolio
minAccept <- 0.01 ##min acceptable weight in porfolio - if lower, will remove and re-optimize

# cat (paste (minAccept, "is the minimum percent of portolio for a species to be used in final portfolio"))

Trees <- unique(SIBEC$TreeSpp)
myColours <- data.table(TreeCode = Trees)
myColours <- cols[myColours, on = "TreeCode"]
myColours <- myColours[!is.na(HexColour),]
pal <- myColours$HexColour
names(pal) <- myColours$TreeCode
colScale <- scale_fill_manual(name = "variable", values = pal)
Trees <- myColours$TreeCode

##set min and max weights for each species
boundDat <- data.table(Spp = Trees)
boundDat[,`:=`(minWt = 0, maxWt = 1)]

##adjust min and max weights (or remove species)
## see below examples
# boundDat[Spp == "Hw",maxWt := 0] ##remove Hw
# boundDat[Spp == "Pl",minWt := 0.1] ## set min weight for Pl to 0.1

boundDat2 <-  data.table::transpose(boundDat) %>% row_to_names (row_number = 1)

##############
notUse <- boundDat$Spp[boundDat$maxWt == 0]
if(length(notUse > 0)){
  Trees <- Trees[!Trees %in% notUse]
}
nSpp <- length(Trees)
treeList <- Trees
```




```{r parallelSetup, results = 'hide'}
##Setup for parallel computing

worker.init <- function(){
    Rcpp::sourceCpp("./CppFunctions/SimGrowth.cpp")
}

require(doParallel)
cl <- makePSOCKcluster(detectCores()-2)
clusterCall(cl, worker.init)
registerDoParallel(cl)
```


```{r portfolio_function, message = TRUE}

pemData <- pemData[!is.na(Site),]
pemData[,Site := ifelse(nchar(Site) < 2, paste0("0",Site),Site)]
pemData <- pemData[Site != "00",]

timePeriods = c(2000,2025,2055)
returnValue = 0.9
treeList <- Trees
nSpp <- length(Trees)

pemPort <- foreach(poly = unique(pemData$PolyID), .combine = loopCombine2) %do% {
  pemCurr <- pemData[PolyID == poly,]
  ss_units <- rep(pemCurr$Site, pemCurr$Sdec)
  cat("Processing polygon",poly,"...\n")
  outAll <- foreach(
  SS = ss_units,
  .combine = loopCombine,
  .packages = c(
    "reshape2",
    "Rcpp",
    "magrittr",
    "reticulate",
    "data.table",
    "foreach",
    "ggplot2",
    "ggthemes",
    "scales"
  ),
  .noexport = c("gs2gw", "simGrowthCBST", "simGrowthCpp"),
  .export = c("cleanData", "loopCombine")
) %dopar% {
  
  reticulate::source_python("./PythonFns/PortfolioOptimisation.py") ##comment out this line if running sequentially
  SSPredBGC <- SS_Subset(SSPredOrig,pos = SS)
  SSList <- unique(SSPredBGC$SSCurrent)
  SSout <-
    foreach(selectBGC = SSList[1], .combine = loopCombine) %do% {
      SSPredAll <- SSPredBGC[SSPredBGC$SSCurrent == selectBGC, ] ##don't need this line?
      
      SiteList <- unique(SSPredAll$SiteNo)
      #SiteList <- rep(SiteList, each = round(15/length(SiteList)))
      SSPredAll <-
        SSPredAll[SSPredAll$SiteNo %in% SiteList &
                    !is.na(SSPredAll$SSprob), ]
      
      SL <- SiteList
      allSitesSpp <- foreach(
        SNum = SL,
        .combine = rbind,
        .packages = c("foreach", "reshape2", "dplyr", "magrittr", "Rcpp"),
        .noexport = c("simGrowthCpp")
      ) %do% {
        #cat("Optimising site",SNum,"...\n")
        SS.sum <-
          cleanData(SSPredAll, SIBEC, SuitTable, SNum, Trees, timePer = timePeriods)
        if (any(is.na(SS.sum$MeanSuit))) {
          warning(
            "Missing Suitability in unit ",
            BGC,
            ", sitenumber ",
            SNum,
            " for ",
            SS.sum$Spp[is.na(SS.sum$MeanSuit)],
            ": They will be filled with suit = 4"
          )
          SS.sum$MeanSuit[is.na(SS.sum$MeanSuit)] <-
            4
        }
        SS.sum$FuturePeriod <-
          as.numeric(SS.sum$FuturePeriod)
        if (length(timePeriods) == 1) {
          temp <- SS.sum
          temp$FuturePeriod <-
            SS.sum$FuturePeriod[1] + 85
          SS.sum <- rbind(SS.sum, temp)
        }
        
        if (!is.null(SS.sum)) {
          annualDat <- data.frame("Year" = seq(2000, 2100, 1))
          
          output <-
            data.frame("year" = annualDat$Year)
          
          for (k in 1:nSpp) {
            ##for each tree
            
            DatSpp <-
              SS.sum[SS.sum$Spp == treeList[k], ]
            
            dat <-
              data.frame(
                "Period" = rescale(as.numeric(DatSpp$FuturePeriod),
                                   to = c(2000, 2085)),
                "SIBEC" = DatSpp$MeanSI,
                "Suit" = DatSpp$MeanSuit
              )
            dat$SIBEC <-
              dat$SIBEC / 50 ##for mean annual increment
            dat <-
              merge(dat, SuitProb, by = "Suit")
            s <-
              approx(dat$Period, dat$SIBEC, n = 101) ##Smooth SI
            p <-
              approx(dat$Period, dat$ProbDead, n = 101) ###Smooth Prob Dead
            m <-
              approx(dat$Period, dat$NoMort, n = 101) ##Smooth No Mort
            
            ###data frame of annual data
            annualDat <-
              data.frame(
                "Year" = seq(2000, 2100, 1),
                "Growth" = s[["y"]],
                "MeanDead" = p[["y"]],
                "NoMort" = m[["y"]]
              ) ##create working data
            
            Returns <- simGrowthCpp(DF = annualDat)
            tmpR <- c(0, Returns)
            assets <- Returns - tmpR[-length(tmpR)]
            temp <-
              data.frame(
                Spp = rep(treeList[k], 101),
                Year = 1:101,
                Returns = Returns
              )
            output <- cbind(output, assets)
          } ## for each tree species
          
          colnames(output) <- c("Year", treeList)
          
          ####Portfolio#######################################
          returns <- output
          rownames(returns) <- returns[, 1]
          returns <- returns[, -1]
          ###only include species with mean return > 1 in portfolio
          use <-
            colnames(returns)[colMeans(returns) > 1] ###should probably be higher
          returns <- returns[, use]
          sigma2 <-
            as.data.frame(cor(returns)) ###to create cov mat from returns
          
          ef <-
            ef_weights_v2(returns, sigma2, boundDat, minAccept)
          ef_w <- ef[[1]]
          ef_w$Sd <- ef[[2]]
          ef_w$Return <- 1:20
          ef_w$RealRet <- ef[[3]]
          ef_w$Sharpe <- ef[[4]]
          
          eff_front2 <- as.data.table(ef_w)
          eff_front2$SiteNo <- SNum
          melt(
            eff_front2,
            id.vars = c("Return", "SiteNo"),
            variable.name = "Spp"
          )
        } else{
          NULL
        }
        
      }
      
      if (!is.null(allSitesSpp)) {
        efAll <- allSitesSpp
        efAll <-
          dcast(
            efAll,
            Return ~ Spp,
            fun.aggregate = function(x) {
              sum(x) / (length(SL))
            }
          )
        efAll <- efAll[complete.cases(efAll), ]
        efAll$RealRet <-
          efAll$RealRet / max(efAll$RealRet) ##standardise return
        RetCurve <- approx(efAll$RealRet, efAll$Sd, xout = returnValue)
        ret90 <- RetCurve$y
        maxSharpe <-
          efAll[efAll$Sharpe == max(efAll$Sharpe), -c("Return", "Sharpe")]
        maxSPos <- maxSharpe$Sd
        maxSharpe <- t(maxSharpe) %>% as.data.frame() %>%
          mutate(Spp = rownames(.)) %>% set_colnames(c("value", "Spp"))
        ret90Props <-
          efAll[which.min(abs(efAll$RealRet - returnValue)), -c("Return", "Sharpe")]
        ret90Props <- t(ret90Props) %>% as.data.frame() %>%
          mutate(Spp = rownames(.)) %>% set_colnames(c("value", "Spp"))
        maxSharpe$SSCurrent <- selectBGC
        maxSharpe$Unit <- SS
        maxSharpe$SetRet <- ret90Props$value
        maxSharpe$SetRet[maxSharpe$Spp == "Sd"] <- ret90
        efAll <- efAll[, -c("Return", "Sharpe")]
        efAll <- melt(efAll, id.vars = "Sd")
        efAll$Unit <- SS
        
        list(GraphDat = efAll, MaxS = maxSharpe)
      }
      
    }
}

dat <- data.table(outAll$MaxS)
dat <- dat[!Spp %chin% c("RealRet","Sd"), .(Weight = mean(value)), by = .(Spp)]
setorder(dat, -Weight)
datAll <- dat
dat <- dat[1:5,]
dat[,Weight := Weight/sum(Weight)]
dat[,Weight := round(Weight*10,digits = 0)]
dat <- dat[Weight != 0,]
dat[,Lab := paste0(Spp,Weight)]
sppLab <- paste(dat$Lab, collapse = "_")
pemCurr$Lab <- paste0(pemCurr$Site,"[",pemCurr$Sdec,"]")
pemLab <- paste0(pemBGC,"/",paste(pemCurr$Lab, collapse = ""))
pSum <- data.frame(Polygon = pemLab,Spp = sppLab)
datAll$PolyLab = pemLab
datAll$PolyID = poly
list(pemSum = pSum, allDat = datAll)
}


```

```{r add to pem}
pemOut <- st_sf(data.frame(pemPort$pemSum,pem))
st_write(pemOut, dsn = paste0(cloud_dir,"PortfolioFiles/QuesnelPem_Portfolios"), 
         layer = "WithPortfolio", driver = "ESRI Shapefile", overwrite = T, append = F)
```

```{r sumTable}
dat <- data.table(pemPort$allDat)
dat <- data.table::dcast(dat, PolyLab ~ Spp, value.var = "Weight")
dat[is.na(dat)] <- 0
pemArea <- pemOut[,c("Polygon","AREA")] %>% st_drop_geometry() %>% as.data.table()
avg <- colMeans(dat[,-1])
dat <- pemArea[dat, on = c(Polygon = "PolyLab")] %>% mutate(AREA = AREA/10000) ###convert to ha from sq m
ft1 <- flextable(dat) %>% colformat_num(digits = 2) %>% set_caption("Portfolio results for each polygon")
ft1

dat2 <- data.table(Spp = names(avg),planting_ratio = avg)
dat2 <- dat2[planting_ratio >= 0.05, .(Spp = Spp,planting_ratio = planting_ratio/sum(planting_ratio))]
dat2[,Area := planting_ratio*sum(dat$AREA)]
dat2[,NumTrees := Area*2066]# 2066 is the number of trees per ha at 2.2m spacing
ft2 <- flextable(dat2) %>% colformat_num(digits = 2) %>% set_caption("Average weighting over whole study area")
ft2
save_as_image(ft2, path = "./outputs/planting_ratio.jpg")
```
